{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Build a custom dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from typing import Iterator, Tuple, List\n",
    "import mads_datasets\n",
    "mads_datasets.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with images is that the size grows pretty fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (180, 180, 3)\n",
    "\n",
    "for i in [1, 10, 100]:\n",
    "    size = (i, ) + image_size\n",
    "    X = np.zeros(size)\n",
    "    size_byte = X.nbytes\n",
    "    print(f\"Size for {i} images: {size_byte / (2**20)} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine what would happen if you actually have a million images! And no, the answer to this\n",
    "is not \"just get more RAM in the cloud\". You actually don't need to store everything at\n",
    "the same time in memory, right? So we will use the dataloader pattern to fix this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow has a nice [collection of datasets](https://www.tensorflow.org/datasets) for machine learning tasks. Let's download the 'flower_photos' dataset. We will use that dataset for image classification later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "flowersfactory = DatasetFactoryProvider.create_factory(DatasetType.FLOWERS)\n",
    "flowersfactory.download_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = flowersfactory.subfolder\n",
    "print(image_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's  build a datagenerator from scratch; even though there are a lot of libraries (tensorflow, pytorch, trax) that provide datagenerators for images, it is a usefull practice to learn how the inside works. \n",
    "\n",
    "Eventually you will encounter a task were you will need to read in data from disk, and it is always usefull if you know how to adapt to a custom case. First step is to list all files in the directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_dir(path: Path) -> Iterator:\n",
    "    \"\"\"loops recursively through a folder\n",
    "\n",
    "    Args:\n",
    "        path (Path): folder to loop trough. If a directory\n",
    "            is encountered, loop through that recursively.\n",
    "\n",
    "    Yields:\n",
    "        Generator: all paths in a folder and subdirs.\n",
    "    \"\"\"\n",
    "\n",
    "    for p in Path(path).iterdir():\n",
    "        if p.is_dir():\n",
    "            yield from walk_dir(p)\n",
    "            continue\n",
    "        # resolve works like .absolute(), but it removes the \"../..\" parts\n",
    "        # of the location, so it is cleaner\n",
    "        yield p.resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first file is a .txt file, so we will need to filter that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = walk_dir(image_folder)\n",
    "file1 = next(paths)\n",
    "file2 = next(paths)\n",
    "file1, file2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we now have a generator of paths in the directory. We can use a path to load an image from disk.\n",
    "The stucture that is often used for storing images is to have subfolders that indicate a label. \n",
    "This is an easy way to create a dataset by a human (just drag and drop the images in the right folder to label them).\n",
    "\n",
    "If the photo is inside the `tulips` subfolder, the class label should be `tulips`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "file = next(paths)\n",
    "img = Image.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iter_valid_paths` function pulls all files, strips the corrects suffixes (we only want images), retrieves the classnames by gathering the names of the subfolders, and returns both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have a look at the available file types\n",
    "from mads_datasets.settings import FileTypes\n",
    "for ft in FileTypes:\n",
    "    print(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_valid_paths(path: Path, formats: List[FileTypes]) -> Tuple[Iterator, List[str]]:\n",
    "    # gets all files in folder and subfolders\n",
    "    walk = walk_dir(path)\n",
    "\n",
    "    # retrieves foldernames as classnames\n",
    "    class_names = [subdir.name for subdir in path.iterdir() if subdir.is_dir()]\n",
    "\n",
    "    # keeps only specified formats\n",
    "    formats_ = [f.value for f in formats]\n",
    "    paths = (path for path in walk if path.suffix in formats_)\n",
    "    return paths, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formats = [FileTypes.JPG]\n",
    "paths, class_names = iter_valid_paths(\n",
    "    path = image_folder / \"flower_photos\",\n",
    "    formats=formats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(paths), class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, last, we need the `load_image` function.\n",
    "\n",
    "While there are multiple libraries available to load images (`pyvips`, `PIL`) the functions from `tensorflow` are the fastest for the sequence of tasks:\n",
    "- load image from disk\n",
    "- decode into an array of numbers\n",
    "- resize the image to a fixed size\n",
    "- cast to `numpy` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath = next(paths)\n",
    "newsize = (150, 150)\n",
    "img_ = Image.open(imgpath).resize(newsize, Image.LANCZOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(img_)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(\n",
    "    path: Path, image_size: Tuple[int, int]\n",
    ") -> np.ndarray:\n",
    "    # load file\n",
    "    img_ = Image.open(path).resize(image_size, Image.LANCZOS)\n",
    "    return np.asarray(img_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit load_image(file, image_size=(180, 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = next(paths)\n",
    "img = load_image(file, (180, 180))\n",
    "type(img), img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the image we loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img.astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
